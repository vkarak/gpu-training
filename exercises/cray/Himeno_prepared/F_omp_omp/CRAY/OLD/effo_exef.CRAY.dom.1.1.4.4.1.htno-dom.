# -----------------------------------------------
# core file size          (blocks, -c) unlimited
# data seg size           (kbytes, -d) unlimited
# scheduling priority             (-e) 0
# file size               (blocks, -f) unlimited
# pending signals                 (-i) 511579
# max locked memory       (kbytes, -l) 64
# max memory size         (kbytes, -m) 65986560
# open files                      (-n) 16384
# pipe size            (512 bytes, -p) 8
# POSIX message queues     (bytes, -q) 819200
# real-time priority              (-r) 0
# stack size              (kbytes, -s) unlimited
# cpu time               (seconds, -t) unlimited
# max user processes              (-u) 511579
# virtual memory          (kbytes, -v) unlimited
# file locks                      (-x) unlimited
# -----------------------------------------------
# -----------------------------------------------
# SLURM_JOB_NODELIST = nid00039
# SLURM_JOB_NUM_NODES = 1
# SLURM_JOB_ID = 655819
# SLURM_JOBID = 655819
# SLURM_NTASKS = 1 / -n --ntasks
# SLURM_NTASKS_PER_NODE = 1 / -N --ntasks-per-node
# SLURM_CPUS_PER_TASK = 4 / -d-c --cpus-per-task
# OMP_NUM_THREADS = 4 / -d-c 
# SLURM_NTASKS_PER_CORE = 1 / -j1 --ntasks-per-core
# -----------------------------------------------
# -----------------------------------------------
# SLURM_CPUS_ON_NODE = 12
# SLURM_LOCALID = 0
# SLURM_NNODES = 1
# SLURM_NODEID = 0
# SLURM_PROCID = 0
# SLURM_NPROCS = 1
# SLURM_OVERCOMMIT = 
# nodeid:0 taskid:0 localid:0
# 
# -----------------------------------------------
Wed Apr 26 17:29:54 CEST 2017
+ echo CRAY_CUDA_MPS=
CRAY_CUDA_MPS=
+ echo HUGETLB_DEFAULT_PAGE_SIZE=
HUGETLB_DEFAULT_PAGE_SIZE=
+ echo HUGETLB_MORECORE=
HUGETLB_MORECORE=
+ /usr/bin/time -p srun --unbuffered --ntasks=1 --ntasks-per-node=1 --cpus-per-task=4 --ntasks-per-core=1 --hint=nomultithread --cpu_bind=rank --bcast=/tmp/exef.CRAY.dom ./exef.CRAY.dom
[CCE OMP: host=nid00039 pid=18814 tid=18814 id=0] thread 0 affinity:  0
[CCE OMP: host=nid00039 pid=18814 tid=18828 id=0] thread 1 affinity:  0
WARNING: Requested total thread count and/or thread affinity may result in
oversubscription of available CPU resources!  Performance may be degraded.
Set OMP_WAIT_POLICY=PASSIVE to reduce resource consumption of idle threads.
Set CRAY_OMP_CHECK_AFFINITY=TRUE to print detailed thread-affinity messages.
WARNING: thread 1 increases the expected utilization of processor 0 to 200.00%
[CCE OMP: host=nid00039 pid=18814 tid=18829 id=0] thread 2 affinity:  0
WARNING: thread 2 increases the expected utilization of processor 0 to 300.00%
[CCE OMP: host=nid00039 pid=18814 tid=18830 id=0] thread 3 affinity:  0
WARNING: thread 3 increases the expected utilization of processor 0 to 400.00%
 OPENMP version: 201307 4   4
 OPENACC version: 201306
 memcopy and daxpy test of size 65536
 -------
 timings
 -------
 axpy (openmp, openacc):  4.33859460172243416E-2   8.24939925223588943E-5 seconds
 copyin     :  0.89488404698204249 s
 copyout    :  1.47533952258527279E-4 s
 TOTAL      :  0.89511407492682338 s
 ============ PASSED
real 3.35
user 1.14
sys 0.17
+ set +x
